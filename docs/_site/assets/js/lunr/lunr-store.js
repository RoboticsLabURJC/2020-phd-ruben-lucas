var store = [{
        "title": "Introduction (months 1 and 2)",
        "excerpt":"The goal this two first months is to land into machine learning and vision recognition world reading some previous master theses and its references to clarify some artificial intelligence basic concepts. Lectures TFM Vanesa Fernández TFM Jéssica Fernández TFM Francisco Pérez TFM Nacho Arranz TFM David Pascual TFM Nacho Condés...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/previous-work/",
        "teaser":null},{
        "title": "Digging in (month 3)",
        "excerpt":"The goal for this month was to set the whole environment to work and start playing with reinforcement learning so the lectures can be consolidated with some exercises. Lectures Thesis of a DQN neural network able to beat an human gamer playing ATARI games Study of the effect of convolutional...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/current-work/",
        "teaser":null},{
        "title": "QLearning and Sarsa (month 4)",
        "excerpt":"The goal of this month is defining from scratch a model-free reinforcement learning algorithm and an environment to solve a typical path learning from source to goal problem. Additionally, some lectures have been useful to accomplish the month objective. Lectures Reinforcement learning algorithms overview When to choose sarsa vs qlearning...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/model_free_qlearning_algorithm/",
        "teaser":null},{
        "title": "QLearning (month 5 · Weeks 1 and 2)",
        "excerpt":"The goal of this two weeks is to solve the mountainCar problem using a reinforced learning algorithm with no neural network. Besides that, this blog will be refined to better show the work progress and learnings. Lectures KL Divergence for Machine Learning Cross entropy loss explanation Unlearning phenomenom in machine...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainCar_qlearning/",
        "teaser":null},{
        "title": "QLearning (month 5 · Weeks 3 and 4)",
        "excerpt":"The goal of this two weeks is to create owr own environment with its own physics so we can lately modify the mountain heigh, the car mass, the maximum velocity, the number of mountains, the goal to be reached, etc. Lectures Physics basics in terms of movemetnt forces Lab work...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainBall_qlearning/",
        "teaser":null},{
        "title": "Projects standarization (month 6)",
        "excerpt":"The goal of this month is to have an homogeneus project structure and an easy to follow projects coding plan (unwritten guidelines) so all of the exercises are organized in the same way. Additionally, the introdction, QLearning and Sarsa sections of the sutton book have been reviewed besides the other...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/standarization/",
        "teaser":null},{
        "title": "Study of first section of sutton book (month 7)",
        "excerpt":"The goal of this month is to fully read the first section of sutton book (8 chapters) and to fully understand the basics of reincorcement learning. Once we got enough background, it will be easier to follow the good practices and state-of-the-art of reinforcement learning. Additionally, since more algorithms will...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/rl_basics_study/",
        "teaser":null},{
        "title": "Introduction to gazebo and rl-studio (months 8 and 9)",
        "excerpt":"The goal of this month is to get in touch with gazebo and rl-studio in order to later work with this and develop our own artifial intelligence models making use of all the gazebo benefits. Since these two months have been quite chaotic (vacations + computer fault) the progress to...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/gazebo_and_rl-studio/",
        "teaser":null},{
        "title": "Learning about RLStudio with basic robot mesh problem (months 10 and 11)",
        "excerpt":"The goal of this month is to finally get a tangible work for robot_mesh problem. In previous weeks, a robot was trained using qlearning to learn how to run from an origin to a destination skiping some obstacles in the shortest path posible. Now, this problem has been migrated to...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/rlstudio_robotmesh/",
        "teaser":null},{
        "title": "Migrating to new RLStudio and migrating mountain car to RLStudio 0.1.0 (Month 12)",
        "excerpt":"The goals of this month are: Migration of the robot_mesh problem to the new RLStudio 0.1.0 getting the mountain car problem working in RLStudio 0.1.0 In the meanwhile: Some ros tutorials has been done to understand how the communication with the robots and the environment occurs. some other modifications were...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/RLStudio_Migration_and_Mountain_car/",
        "teaser":null},{
        "title": "Still migrating mountain car to RL-Studio and year 1 phd formalization (Month 13 - First half)",
        "excerpt":"The goals of this month are: enroll in the doctoral program for the second year and pay the fees. Propperly share the robot mesh implementation and videos both in github (via pull request) and slack (via forum posting) write the first prototype of the investigation plan which will be followed...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/year_summary_and_mountain_car_debugging/",
        "teaser":null},{
        "title": "Final implementation of mountain_car basic scenario (Month 13 - Second half)",
        "excerpt":"The goals of this two weeks were: get a productive solution for the mountain-car problem in RL-Studio 0.1.0. Allig whith the rest of the JDeRobot team so we cooperate to evolve RL-Studio. Regarding the mountain car adaptation/migration, the following actions has been performed to make the simple environment built in...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountain_car_final_migration_to_RLStudio_0.1.0/",
        "teaser":null},{
        "title": "Projects polishing pre-integration with RL-Studio 1.1.0 (month 14)",
        "excerpt":"We are about to integrate the robot mesh and mountain car into RL-Studio 1.1.0, so no new problems will be addressed. However, while revisitting the problems and algorithms already integrated into RL-Studio 0.1.0 (Note that the review was needed because I came back from a job movement and I needed...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/your%20category/projects-polishing/",
        "teaser":null},{
        "title": "Robot following path to goal with q learning and sarsa",
        "excerpt":"Reqs To execute this program you just need to install the following libraries: Python3 PyQt5 numpy Pandas matplotlib Manual The main goal of this kind of exercises is to learn how to develop a simple reinforced learning algorithm to make an agent learn the optimal path to the goal as...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/projects/2021-01-08-model_free_qlearning_algorithm/",
        "teaser":null},{
        "title": "MountainCar openAI Gym exercise solved using q learning",
        "excerpt":"Reqs To execute this program you just need to install the following libraries: Python3 PyQt5 numpy Pandas matplotlib Manual The main goal of this exercise is similar to the last proposed. To dig into the reinforcement learning basics. In this case, the exercise is not that simple, since some times...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/projects/2021-01-22-mountainCar_qlearning/",
        "teaser":null},{
        "title": "MountainCar customized environment making use of OpenAI Gym libraries",
        "excerpt":"Reqs To execute this program you just need to install the following libraries: Python3.7 PyQt5 numpy 1.16.5 Pandas matplotlib tensorflow 1.14.0 gym sympy stable-baselines Manual The main goal of this exercise is being able to configure owr own environment with its own physics. The biggest challenge here was to make...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/projects/2021-02-07-customized-mountainCar/",
        "teaser":null},{
        "title": "MountainCar openAI Gym exercise revisited after reading sutton section 1",
        "excerpt":"After reading the section I of sutton reinforcement learning book, the previous implementation of the proposed openAIGym exercise “mountainCar” has been reviewed. This revision consisted of: Updating the reward function so it is simpler and alligned with theoretical basics of reinforcement learning. Playing with the initialization of the q_table used...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/projects/2021-03-21-revisited_mountain_car/",
        "teaser":null},{
        "title": "Migration to RLStudio of basic robot mesh problem",
        "excerpt":"After running the Nacho TFM and understanding how the training and inferencing work, the previous practice “robot_mesh” has been migrated to RL-Studio. This migration consisted of: Migrating the learning algorithm to make the robot behave well in maze problem. Adapt robot actions to step from one maze cell to the...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/projects/2021-07-26-RLStudio_robotmesh/",
        "teaser":null},{
        "title": "Migration to RLStudio of mountain car problem proposed by openAI-gym",
        "excerpt":"This migration consisted of: Creating models and world for mountain car problem. Ensuring actions doesnt provoke and unconsistent state (robot must always be within the “mountain” platform and move just to right and left). Ensure actions efforts make the problem reachable but considerably difficult so we can take benefit of...","categories": ["your category"],
        "tags": ["tag 1","tag 2","tag 3","tag 4"],
        "url": "http://localhost:4000/2020-phd-ruben-lucas/projects/2022-01-07-RLStudio_mountain_car/",
        "teaser":null}]
