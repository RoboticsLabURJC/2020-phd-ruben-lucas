<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/2020-phd-ruben-lucas/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/2020-phd-ruben-lucas/" rel="alternate" type="text/html" /><updated>2021-02-07T04:11:28-08:00</updated><id>http://localhost:4000/2020-phd-ruben-lucas/feed.xml</id><title type="html">Robotics Lab URJC</title><subtitle>Programming Robot Intelligence</subtitle><author><name>Rubén Lucas</name></author><entry><title type="html">QLearning (month 5 · Weeks 3 and 4)</title><link href="http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainBall_qlearning/" rel="alternate" type="text/html" title="QLearning (month 5 · Weeks 3 and 4)" /><published>2021-02-07T00:00:00-08:00</published><updated>2021-02-07T00:00:00-08:00</updated><id>http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainBall_qlearning</id><content type="html" xml:base="http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainBall_qlearning/">&lt;p&gt;The goal of this two weeks is to create owr own environment with its own physics so
we can lately modify the mountain heigh, the car mass, the maximum velocity, the
number of mountains, the goal to be reached, etc.&lt;/p&gt;

&lt;h2 id=&quot;lectures&quot;&gt;Lectures&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sc.ehu.es/sbweb/fisica/dinamica/con_mlineal/cuna/cuna.htm&quot;&gt;Physics basics in terms of movemetnt forces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lab-work&quot;&gt;Lab work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas/tree/master/mountain_ball&quot;&gt;mountainBall configurable environment and similar to mountainCar environment with qlearning solution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rubén Lucas</name></author><category term="your category" /><category term="tag 1" /><category term="tag 2" /><category term="tag 3" /><category term="tag 4" /><summary type="html">creating our own environment to freely configure our own problem</summary></entry><entry><title type="html">QLearning (month 5 · Weeks 1 and 2)</title><link href="http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainCar_qlearning/" rel="alternate" type="text/html" title="QLearning (month 5 · Weeks 1 and 2)" /><published>2021-01-22T00:00:00-08:00</published><updated>2021-01-22T00:00:00-08:00</updated><id>http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainCar_qlearning</id><content type="html" xml:base="http://localhost:4000/2020-phd-ruben-lucas/your%20category/mountainCar_qlearning/">&lt;p&gt;The goal of this two weeks is to solve the mountainCar problem using a reinforced learning algorithm with no neural network. 
Besides that, this blog will be refined to better show the work progress and learnings.&lt;/p&gt;

&lt;h2 id=&quot;lectures&quot;&gt;Lectures&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://dibyaghosh.com/blog/probability/kldivergence.html&quot;&gt;KL Divergence for Machine Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation&quot;&gt;Cross entropy loss explanation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://insights.daffodilsw.com/blog/machine-unlearning-what-it-is-all-about&quot;&gt;Unlearning phenomenom in machine learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lab-work&quot;&gt;Lab work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas/tree/master/openAI_exercises/mountainCar/qlearning&quot;&gt;mountainCar openAIGym exercise with qlearning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rubén Lucas</name></author><category term="your category" /><category term="tag 1" /><category term="tag 2" /><category term="tag 3" /><category term="tag 4" /><summary type="html">Solving a more complex problem using qlearning</summary></entry><entry><title type="html">QLearning and Sarsa (month 4)</title><link href="http://localhost:4000/2020-phd-ruben-lucas/your%20category/model_free_qlearning_algorithm/" rel="alternate" type="text/html" title="QLearning and Sarsa (month 4)" /><published>2021-01-08T00:00:00-08:00</published><updated>2021-01-08T00:00:00-08:00</updated><id>http://localhost:4000/2020-phd-ruben-lucas/your%20category/model_free_qlearning_algorithm</id><content type="html" xml:base="http://localhost:4000/2020-phd-ruben-lucas/your%20category/model_free_qlearning_algorithm/">&lt;p&gt;The goal of this month is defining from scratch a model-free reinforcement learning algorithm and an environment to solve a typical path learning from source to goal problem. Additionally, some lectures have been useful to accomplish the month objective.&lt;/p&gt;

&lt;h2 id=&quot;lectures&quot;&gt;Lectures&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc&quot;&gt;Reinforcement learning algorithms overview&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/326788/when-to-choose-sarsa-vs-q-learning#:~:text=In%20Q%20learning%2C%20you%20update,and%20take%20the%20same%20action.&quot;&gt;When to choose sarsa vs qlearning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://medium.com/@violante.andre/simple-reinforcement-learning-temporal-difference-learning-e883ea0d65b0&quot;&gt;Temporal difference learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://neptune.ai/blog/model-based-and-model-free-reinforcement-learning-pytennis-case-study&quot;&gt;Model ffree vs model based reiforcement learning algorithms (Pytennis case example)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/on-policy-v-s-off-policy-learning-75089916bc2f&quot;&gt;Off-policy vs on-policy reinforcement algorithm&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lab-work&quot;&gt;Lab work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas/tree/master/robot_mesh&quot;&gt;Path learning to reach a goal using qlearning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rubén Lucas</name></author><category term="your category" /><category term="tag 1" /><category term="tag 2" /><category term="tag 3" /><category term="tag 4" /><summary type="html">Start playing with reinforcement learning</summary></entry><entry><title type="html">Digging in (month 3)</title><link href="http://localhost:4000/2020-phd-ruben-lucas/your%20category/current-work/" rel="alternate" type="text/html" title="Digging in (month 3)" /><published>2020-12-23T00:00:00-08:00</published><updated>2020-12-23T00:00:00-08:00</updated><id>http://localhost:4000/2020-phd-ruben-lucas/your%20category/current-work</id><content type="html" xml:base="http://localhost:4000/2020-phd-ruben-lucas/your%20category/current-work/">&lt;p&gt;The goal for this month was to set the whole environment to work and start playing with reinforcement learning so the lectures can be consolidated with some exercises.&lt;/p&gt;

&lt;h2 id=&quot;lectures&quot;&gt;Lectures&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf&quot;&gt;Thesis of a DQN neural network able to beat an human gamer playing ATARI games&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://dialnet.unirioja.es/descarga/articulo/4902816.pdf&quot;&gt;Study of the effect of convolutional masks making use of the Fourier Transform&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-5-monte-carlo-and-temporal-difference-learning-889053aba07d&quot;&gt;Reinforcement learning introduction&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html&quot;&gt;DDPG introduction&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=t3fbETsIBCY&quot;&gt;DQN introduction and implementation explanation video&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://adgefficiency.com/dqn-tuning/&quot;&gt;DQN hyperparameters tunning using openAI cartpole exercise&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lab-work&quot;&gt;Lab work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;OpenAi gym installation and the acomplishment of the exercises explained in &lt;a href=&quot;https://towardsdatascience.com/solving-reinforcement-learning-classic-control-problems-openaigym-1b50413265dd&quot;&gt;Shiva Verma’s blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rubén Lucas</name></author><category term="your category" /><category term="tag 1" /><category term="tag 2" /><category term="tag 3" /><category term="tag 4" /><summary type="html">Start playing with reinforcement learning</summary></entry><entry><title type="html">Introduction (months 1 and 2)</title><link href="http://localhost:4000/2020-phd-ruben-lucas/your%20category/previous-work/" rel="alternate" type="text/html" title="Introduction (months 1 and 2)" /><published>2020-11-29T00:00:00-08:00</published><updated>2020-11-29T00:00:00-08:00</updated><id>http://localhost:4000/2020-phd-ruben-lucas/your%20category/previous-work</id><content type="html" xml:base="http://localhost:4000/2020-phd-ruben-lucas/your%20category/previous-work/">&lt;p&gt;The goal this two first months is to land into machine learning and vision recognition world reading some previous master theses and its references to clarify some artificial intelligence basic concepts.&lt;/p&gt;

&lt;h2 id=&quot;lectures&quot;&gt;Lectures&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-deeplearning_autonomous_navigation-vanessa-2020.pdf&quot;&gt;TFM Vanesa Fernández&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-deeplearning_traffic_sensor-jessica-2020.pdf&quot;&gt;TFM Jéssica Fernández&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-deeplearning-autonomous_navigation-francisco_perez-2020.pdf&quot;&gt;TFM Francisco Pérez&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-reinforcementlearning-conduccion_autonoma-ignacio_arranz-2020.pdf&quot;&gt;TFM Nacho Arranz&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-deeplearning-human_pose-david_pascual-2020.pdf&quot;&gt;TFM David Pascual&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-deeplearning-person_following-nacho_condes-2020.pdf&quot;&gt;TFM Nacho Condés&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/students/tfm-deeplearning-prediccion_fotogramas-nuria_oyaga-2020.pdf&quot;&gt;TFM Nuria Oyaga&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gsyc.urjc.es/jmplaza/draft-detectionstudio.pdf&quot;&gt;Detection Studio review&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lab-work&quot;&gt;Lab work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Objects Detector installation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Detection Studio installation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Atom installation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jekyll+GitPages installation and blog creation&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Tony Stark</name></author><category term="your category" /><category term="tag 1" /><category term="tag 2" /><category term="tag 3" /><category term="tag 4" /><summary type="html">Landing on vision recognition basics</summary></entry></feed>