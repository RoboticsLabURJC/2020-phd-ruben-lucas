<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.5 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Robot following path to goal with q learning and sarsa - Robotics Lab URJC</title>
<meta name="description" content="Using q learning and sarsa to learn a path from origin to destination through a mesh board">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Robotics Lab URJC">
<meta property="og:title" content="Robot following path to goal with q learning and sarsa">
<meta property="og:url" content="http://localhost:4000/2020-phd-ruben-lucas/projects/2021-01-08-model_free_qlearning_algorithm/">


  <meta property="og:description" content="Using q learning and sarsa to learn a path from origin to destination through a mesh board">







  <meta property="article:published_time" content="2021-01-08T00:00:00-08:00">





  

  


<link rel="canonical" href="http://localhost:4000/2020-phd-ruben-lucas/projects/2021-01-08-model_free_qlearning_algorithm/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "JdeRobot",
      "url": "http://localhost:4000/2020-phd-ruben-lucas",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/2020-phd-ruben-lucas/feed.xml" type="application/atom+xml" rel="alternate" title="Robotics Lab URJC Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/2020-phd-ruben-lucas/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="icon" type="image/png" href="/assets/images/logo.png" sizes="16x16">
<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/2020-phd-ruben-lucas/"><img src="/2020-phd-ruben-lucas/assets/images/peloto.png" alt=""></a>
        
        <a class="site-title" href="/2020-phd-ruben-lucas/">
          Robotics Lab URJC
          <span class="site-subtitle">Programming Robot Intelligence</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/2020-phd-ruben-lucas/logbook/" >LogBook</a>
            </li><li class="masthead__menu-item">
              <a href="/2020-phd-ruben-lucas/install/" >Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/2020-phd-ruben-lucas/about/" >Resources</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">LogBook</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/2020-phd-ruben-lucas/logbook/" class="">Check it out</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Projects</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/2020-phd-ruben-lucas/install/" class="">AI Exercises</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Resources</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/2020-phd-ruben-lucas/references/" class="">Usefull resources</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>
    
  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Robot following path to goal with q learning and sarsa">
    <meta itemprop="description" content="Using q learning and sarsa to learn a path from origin to destination through a mesh board">
    <meta itemprop="datePublished" content="January 08, 2021">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Robot following path to goal with q learning and sarsa
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  3 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-cog"></i> TOC installation</h4></header>
              <ul class="toc__menu">
  <li><a href="#reqs">Reqs</a></li>
  <li><a href="#manual">Manual</a></li>
  <li><a href="#videos">Videos</a></li>
  <li><a href="#code">Code</a></li>
  <li><a href="#results">Results</a></li>
</ul>
            </nav>
          </aside>
        
        <h2 id="reqs">Reqs</h2>

<p>To execute this program you just need to install the following libraries:</p>
<ul>
  <li>Python3</li>
  <li>PyQt5</li>
  <li>numpy</li>
  <li>Pandas</li>
  <li>matplotlib</li>
</ul>

<h2 id="manual">Manual</h2>

<p>The main goal of this kind of exercises is to learn how to develop a simple reinforced learning algorithm to make an agent learn the optimal path to the goal as soon as possible.
The provided environment gives the possibility to perform one of four actions (“go up”, “go down”, “go left” and “go right”) each simulation step to try getting closer to the location/state in the board which was configured as goal.</p>

<p><strong>GRAPHS:</strong></p>

<p>To learn the behaviour of our agent based on what we are implementing it is important to have any kind of metric to measure the performance of each test.
To accomplish that we have two graphs in the upper part of a window that will be prompted each time the agent complete a configured number of maximum attempts to reach the goal.</p>

<ul>
  <li>
    <p>The first graph indicates how good the agent is learning a path so the total reward is for each run increases. This graph shows the total reward per run.</p>
  </li>
  <li>
    <p>The second graph indicates how many steps were needed in each run to either reach the goal or fail (getting out of the board or stepping a bomb)</p>
  </li>
</ul>

<p><strong>BOARD:</strong></p>

<p>Nevertheless, to ease the analysis of each try, it is always a good idea to represent the real scenario as clos to reality as possible. For that reason, a board is represented in the down side of the window with the number of times our agent steps each cell of the board before finishing the run. To better have an idea of the final learning of our agent we will display the most recurrents paths followed and the number of occurrences of those paths.</p>

<p><strong>CONFIGURATION</strong></p>

<p>Instead of not being really configurable, the code is easily modifiable to try different scenarios and to visualize more or less number of occurrences. In order to do so, comments and constants with descriptive names have been added at the beginning of the code.
Nevertheless, the main constants that take part in this configuration are described below:</p>

<p>To configure the environment open the environment.py file and adjust the following parameters according to your needs:</p>

<ul>
  <li><b>NUM_OF_X_BLOCKS</b>: Number of the board blocks in x axis</li>
  <li><b>NUM_OF_Y_BLOCKS</b>: Number of the board blocks in y axis</li>
  <li><b>INIT_Y</b>: Initial position that the robot will occupy in the board y axis</li>
  <li><b>INIT_X</b>: Initial position that the robot will occupy in the board x axis</li>
  <li><b>BLOCKS</b>: list containing the meaning of each cell in the board (“GOAL”, “BOMB”, “OK”)</li>
</ul>

<p>To configure the algorithm that will be used to solve the problem adjust the following hyperparameters in robot_mesh.py file:</p>

<ul>
  <li><b>GAMMA</b></li>
  <li><b>LEARNING RATE</b></li>
  <li><b>EXPLORATION_MIN</b></li>
  <li><b>EXPLORATION_DECAY</b></li>
</ul>

<p>And finally, to visualize the desired number of last occurrences, configure the constant “NUMBER_OF_LAST_OCCURRENCES_TO_PLOT” in robot_mesh.py (E.g If configured to 10, then the last 10 occurrences will be shown in the “results window” displayed at the end of the program execution)</p>

<h2 id="videos">Videos</h2>

<iframe width="560" height="315" src="https://www.youtube.com/embed/5pHcHyNFSP4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p><br /></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/HHlRMhiZWCM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="code">Code</h2>

<p><a href="https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas/tree/master/RL_Unibotics/roboticsLab_exercises/robot_mesh/absolute_positions/">Path learning to reach a goal using qlearning</a></p>

<h2 id="results">Results</h2>

<p>The easiest and fastest way to solve this problem was proved to be q learning. After some hyperparameters tunnings to improve the performance and some differents maps tested, the chosen map to exemplify the problem results is the following:</p>

<p><img src="/2020-phd-ruben-lucas/assets/images/results_images/robotmesh/mapqlearning.png" alt="map" class="img-responsive" /></p>

<p>Being the green cells the start and end points, the black cells the bombs that the “robot” must avoid and the blue cells the optimal path to achieve the goal.
The winners hyperparameters have been the following:</p>

<ul>
  <li>GAMMA = 0.95</li>
  <li>LEARNING RATE = 0.9</li>
  <li>EXPLORATION_MIN = 0.000001</li>
  <li>EXPLORATION_DECAY = 0.999</li>
</ul>

<p>And the results, as shown in the video are indicated within the following graphics:</p>

<p><img src="/2020-phd-ruben-lucas/assets/images/results_images/robotmesh/resultsqlearning.png" alt="results" class="img-responsive" /></p>

<p>As you can see, the algorithm converges around the simulation 450, from which all the paths followed were the optimal.</p>

<p>After this experiment I felt it was not enough and Sarsa was implemented to solve the same problem.
Note that Sarsa tries to converge with as less risk as possible, avoiding paths close to a low reward. For that reason, the map shown in the q learning example never converged using Sarsa. Once the map was a little more clear with wider paths to the goal, Sarsa got to learn a path to the goal even not being the optimal one.
You can find the explanation of this in the best answer to <a href="https://stats.stackexchange.com/questions/326788/when-to-choose-sarsa-vs-q-learning">this question</a>.</p>

<p>that said, having this map:</p>

<p><img src="/2020-phd-ruben-lucas/assets/images/results_images/robotmesh/mapsarsa.png" alt="map" class="img-responsive" /></p>

<p>And the following chosen hyperparameters:</p>

<ul>
  <li>GAMMA = 0.9</li>
  <li>LEARNING RATE = 0.9</li>
  <li>EXPLORATION_MIN = 0.001</li>
  <li>EXPLORATION_DECAY = 0.9995</li>
</ul>

<p>Those are the (obvously worse) results:</p>

<p><img src="/2020-phd-ruben-lucas/assets/images/results_images/robotmesh/resultssarsa.png" alt="results" class="img-responsive" /></p>

<p><span style="color:green"><em>Feel free to share a better implementation or discrepancies with our conclussions!! We are humbly open to learn more from more experts!!</em></span></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/2020-phd-ruben-lucas/tags/#tag-1" class="page__taxonomy-item" rel="tag">tag 1</a><span class="sep">, </span>
    
      
      
      <a href="/2020-phd-ruben-lucas/tags/#tag-2" class="page__taxonomy-item" rel="tag">tag 2</a><span class="sep">, </span>
    
      
      
      <a href="/2020-phd-ruben-lucas/tags/#tag-3" class="page__taxonomy-item" rel="tag">tag 3</a><span class="sep">, </span>
    
      
      
      <a href="/2020-phd-ruben-lucas/tags/#tag-4" class="page__taxonomy-item" rel="tag">tag 4</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/2020-phd-ruben-lucas/categories/#your-category" class="page__taxonomy-item" rel="tag">your category</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-01-08T00:00:00-08:00">January 08, 2021</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Robot+following+path+to+goal+with+q+learning+and+sarsa%20http%3A%2F%2Flocalhost%3A4000%2F2020-phd-ruben-lucas%2Fprojects%2F2021-01-08-model_free_qlearning_algorithm%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <!--<a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F2020-phd-ruben-lucas%2Fprojects%2F2021-01-08-model_free_qlearning_algorithm%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>-->

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2F2020-phd-ruben-lucas%2Fprojects%2F2021-01-08-model_free_qlearning_algorithm%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">Previous</a>
    
    
      <a href="/2020-phd-ruben-lucas/projects/2021-01-22-mountainCar_qlearning/" class="pagination--pager" title="MountainCar openAI Gym exercise solved using q learning
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-phd-ruben-lucas/your%20category/standarization/" rel="permalink">projects standarization (month 6 · Weeks 1 and 2)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Standarizing the project folders and the exercises code structure
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-phd-ruben-lucas/your%20category/mountainBall_qlearning/" rel="permalink">QLearning (month 5 · Weeks 3 and 4)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">creating our own environment to freely configure our own problem
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-phd-ruben-lucas/your%20category/mountainCar_qlearning/" rel="permalink">QLearning (month 5 · Weeks 1 and 2)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Solving a more complex problem using qlearning
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-phd-ruben-lucas/your%20category/model_free_qlearning_algorithm/" rel="permalink">QLearning and Sarsa (month 4)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Start playing with reinforcement learning
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://www.linkedin.com/in/ruben-lucas-zaragoza/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin-in" aria-hidden="true"></i> Linkedn</a></li>
        
      
        
          <li><a href="https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.youtube.com/channel/UC8Kl0ECm4gjhxSozBqghQLQ" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> Youtube</a></li>
        
      
    

    <li><a href="/2020-phd-ruben-lucas/feed.xml"><!--<i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed--></a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 JdeRobot. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a>, <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a> &amp; modified by <a href="https://github.com/igarag">NachoAz</a>.</div>

      </footer>
    </div>

    
  <script src="/2020-phd-ruben-lucas/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       extensions: ["tex2jax.js"],
       jax: ["input/TeX", "output/HTML-CSS"],
       tex2jax: {
         inlineMath: [ ['$','$'], ["\\(","\\)"] ],
         displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
         processEscapes: true
       },
       "HTML-CSS": { availableFonts: ["TeX"] }
     });
  </script>










  </body>
</html>
