I"É<p>The goal of this month is defining from scratch a model-free reinforcement learning algorithm and an environment to solve a typical path learning from source to goal problem. Additionally, some lectures have been useful to accomplish the month objective.</p>

<h2 id="lectures">Lectures</h2>

<ul>
  <li>
    <p><a href="https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc">Reinforcement learning algorithms overview</a></p>
  </li>
  <li>
    <p><a href="https://stats.stackexchange.com/questions/326788/when-to-choose-sarsa-vs-q-learning#:~:text=In%20Q%20learning%2C%20you%20update,and%20take%20the%20same%20action.">When to choose sarsa vs qlearning</a></p>
  </li>
  <li>
    <p><a href="https://medium.com/@violante.andre/simple-reinforcement-learning-temporal-difference-learning-e883ea0d65b0">Temporal difference learning</a></p>
  </li>
  <li>
    <p><a href="https://neptune.ai/blog/model-based-and-model-free-reinforcement-learning-pytennis-case-study">Model ffree vs model based reiforcement learning algorithms (Pytennis case example)</a></p>
  </li>
  <li>
    <p><a href="https://towardsdatascience.com/on-policy-v-s-off-policy-learning-75089916bc2f">Off-policy vs on-policy reinforcement algorithm</a></p>
  </li>
</ul>

<h2 id="lab-work">Lab work</h2>

<ul>
  <li><a href="https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas/tree/master/robot_mesh">Path learning to reach a goal using qlearning</a></li>
</ul>
:ET