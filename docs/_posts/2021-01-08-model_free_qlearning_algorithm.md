---
title: "QLearning and Sarsa (month 4)"
excerpt: "Start playing with reinforcement learning"

sidebar:
  nav: "docs"

toc: true
toc_label: "TOC installation"
toc_icon: "cog"


categories:
- your category
tags:
- tag 1
- tag 2
- tag 3
- tag 4

author: Rub√©n Lucas
pinned: false
---

The goal of this month is defining from scratch a model-free reinforcement learning algorithm and an environment to solve a typical path learning from source to goal problem. Additionally, some lectures have been useful to accomplish the month objective.

## Lectures

- [Reinforcement learning algorithms overview](https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc)

- [When to choose sarsa vs qlearning](https://stats.stackexchange.com/questions/326788/when-to-choose-sarsa-vs-q-learning#:~:text=In%20Q%20learning%2C%20you%20update,and%20take%20the%20same%20action.)

- [Temporal difference learning](https://medium.com/@violante.andre/simple-reinforcement-learning-temporal-difference-learning-e883ea0d65b0)

- [Model ffree vs model based reiforcement learning algorithms (Pytennis case example)](https://neptune.ai/blog/model-based-and-model-free-reinforcement-learning-pytennis-case-study)

- [Off-policy vs on-policy reinforcement algorithm](https://towardsdatascience.com/on-policy-v-s-off-policy-learning-75089916bc2f)


## Lab work

- [Path learning to reach a goal using qlearning](https://github.com/RoboticsLabURJC/2020-phd-ruben-lucas/tree/master/RL_Unibotics/roboticsLab_exercises/robot_mesh/absolute_positions)
